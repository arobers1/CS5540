{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167da8a7-2558-41d0-ae48-325a5dd16043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV,GroupShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GroupKFold\n",
    "# Import the necessary metric\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from scipy.stats import mannwhitneyu\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e3455b-badf-4924-9f50-363cdf72b8bb",
   "metadata": {},
   "source": [
    "### Raw Read Count data (Getting it ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8a2c93-029a-4005-8764-0f08d2ea05a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir_path = Path.cwd().parent\n",
    "\n",
    "## Deal with Braken\n",
    "path_braken = dir_path/'SHINE_Bracken_Data/All_SHINE_Braken_tidy_read_data.csv'\n",
    "braken=pd.read_csv(path_braken)\n",
    "braken_df = pd.DataFrame(braken)\n",
    "contamination = braken_df.filter(regex='virus|Homo sapiens') #remove contamination\n",
    "braken_df = braken_df.drop(columns=contamination.columns)\n",
    "\n",
    "\n",
    "\n",
    "## Deal with the meta data\n",
    "path2 = dir_path/'SHINE_Bracken_Data/MP_Data_SHINE_ID_Patient_ID_no_dups.csv'\n",
    "Meta_data = pd.read_csv(path2)\n",
    "Meta_data_df = pd.DataFrame(Meta_data)\n",
    "Meta_data_df =Meta_data_df[(Meta_data_df.duplicated(subset=['SubjectID_child', 'visitlabel'], keep='first'))|(~Meta_data_df.duplicated(subset=['SubjectID_child', 'visitlabel'], keep=False))].reset_index(drop=True)\n",
    "Meta_data_df\n",
    "\n",
    "#merge Meta_data_df with Braken read data\n",
    "Braken_Meta_merge_df = Meta_data_df.merge(braken_df, left_on='run_accession', right_on='sample')\n",
    "Braken_Meta_merge_df = Braken_Meta_merge_df[(Braken_Meta_merge_df.duplicated(subset=['SubjectID_child', 'visitlabel'], keep='first'))|(~Braken_Meta_merge_df.duplicated(subset=['SubjectID_child', 'visitlabel'], keep=False))].drop(columns='sample').reset_index(drop=True)\n",
    "Dominant_species_path = pd.read_csv(dir_path/'SHINE_Bracken_Data/Dominant_Species_All_Bracken_G8tr1.csv')\n",
    "Dominant_species_df = pd.DataFrame(Dominant_species_path)\n",
    "\n",
    "Braken_meta_dominant_df = Braken_Meta_merge_df[['run_accession','SubjectID_child','visitlabel']+list(Dominant_species_df.columns)] #dataframe of braken dom species with patient id and ERR#\n",
    "\n",
    "\n",
    "#find Ecoli Coptr samples\n",
    "Coptr_path = pd.read_csv(dir_path/'SHINE_COPTR_Data/Coptr_tiddy_df.csv')\n",
    "All_Coptr_df = pd.DataFrame(Coptr_path)\n",
    "Coptr_Meta_merge_df = Meta_data_df.drop(columns=['SubjectID_child','SHINE_ID','visitlabel','age','age_group']).merge(All_Coptr_df, left_on='run_accession',right_on='Sample')\n",
    "Coptr_Meta_merge_df.drop(columns='run_accession',inplace=True)\n",
    "\n",
    "#Get Ecoli samples \n",
    "Samples_w_Your_Species_rates = Coptr_Meta_merge_df[Coptr_Meta_merge_df['Escherichia coli']>0]['Sample'] # change to species name that you want \n",
    "Coptr_Ecoli_df = Coptr_Meta_merge_df[Coptr_Meta_merge_df['Sample'].isin(Samples_w_Your_Species_rates)]\n",
    "#Coptr_Ecoli_GR = Coptr_Ecoli_df['Escherichia coli']\n",
    "#Coptr_Ecoli_GR_df = pd.DataFrame(Coptr_Ecoli_GR)\n",
    "#Coptr_Ecoli_GR_df.reset_index(drop=True, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "#match with Braken\n",
    "Samples_w_Your_Species_Braken_data_df = Braken_meta_dominant_df[Braken_meta_dominant_df['run_accession'].isin(Samples_w_Your_Species_rates)]\n",
    "#put together \n",
    "All_Coptr_E_Coli_GR = Coptr_Ecoli_df[['Sample','Escherichia coli']]  #dataframe of sample number and Ecoli Growth rate \n",
    "our_coptr_EC_GR = All_Coptr_E_Coli_GR[All_Coptr_E_Coli_GR['Sample'].isin(Samples_w_Your_Species_Braken_data_df['run_accession'])] ##make sure we get Coptr data(ecoli gr samples) that are in our braken data \n",
    "\n",
    "Full_data = Samples_w_Your_Species_Braken_data_df.merge(our_coptr_EC_GR, left_on = 'run_accession', right_on='Sample').drop(columns='Sample').rename(columns={'Escherichia coli_y':'Ecoli_GR'})\n",
    "\n",
    "Full_data_copy = Full_data.copy()\n",
    "psuedocount = 0.1\n",
    "Full_data_copy = Full_data_copy.applymap(lambda x: psuedocount if x ==0 else x)\n",
    "\n",
    "Full_data_copy.drop(columns= ['Escherichia phage vB_EcoS-Ro145c2YLVW','Escherichia phage vB_EcoS_fFiEco03','Escherichia phage 26','Escherichia phage SZH-1','Salmonella phage vB_SAg-RPN213'],inplace=True)\n",
    "\n",
    "Full_data_copy.columns = Full_data_copy.columns.str.replace(r'[^A-Za-z0-9_]', '', regex=True)\n",
    "Full_data_copy.columns = Full_data_copy.columns.str.replace(' ', '_')\n",
    "Full_data_copy = Full_data_copy.loc[:, ~Full_data_copy.columns.duplicated()]\n",
    "Full_data_copy \n",
    "#psuedocount = 0.1\n",
    "#Samples_w_Your_Species_Braken_w_psuedo = Samples_w_Your_Species_Braken_data_df_copy.applymap(lambda x: psuedocount if x ==0 else x)\n",
    "#Samples_w_Your_Species_Braken_data_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cb77c7-3052-49bf-a107-d8e2a3bec13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_data.to_csv('Full_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ce5a22-0b5b-47f4-ab8b-427e37655d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_data_copy.to_csv('Full_data_copy.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c6f81f-518b-4e12-bdd4-a738692057f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(Full_data_copy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705aaabc-39da-4790-9cc2-287636cc9d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.linspace(0.01, 0.1, 10)\n",
    "#np.arange(50, 500, 50)\n",
    "np.arange(0,.5,.01)\n",
    "np.linspace(0.01, 0.07, 14)\n",
    "np.arange(0.01, 0.07, .001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baf6813-d404-43ff-b6c0-be02eaa1cc40",
   "metadata": {},
   "source": [
    "# Train/Test Split Strategies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a297fa-b76d-4469-8a36-c57ee7f0278c",
   "metadata": {},
   "source": [
    "### Random Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6c443c-bcb2-4bb7-99f3-c019bf2630a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_split(data,number):\n",
    "    # Separate the data into features and target (X and Y)\n",
    "    X = data.drop(columns=['run_accession', 'SubjectID_child', 'visitlabel', 'Ecoli_GR'])\n",
    "    # Target variable (Ecoli_Growth_rate)\n",
    "    Y = data['Ecoli_GR']\n",
    "    \n",
    "    # Set up lists for model performance\n",
    "    best_models = []   \n",
    "    validation_score_list = []\n",
    "    test_scores_list = []\n",
    "    r2_list = []\n",
    "    \n",
    "    # Set up lists for the random model\n",
    "    random_best_models = []\n",
    "    random_valid_score_list = []\n",
    "    random_test_scores_list = []\n",
    "    random_r2_list = []\n",
    "\n",
    "\n",
    "    # Define hyperparameters grid for the real model\n",
    "    param_grid = {\n",
    "        'num_leaves': np.arange(2, 25, 2),  # Range from 2 to 24 with a step of 2\n",
    "        'max_depth': np.arange(2, 30),  # Range from 1 to 10\n",
    "        'min_split_gain': np.arange(0,.5,.01),\n",
    "        'learning_rate': np.arange(0.01, 0.07, .001),  # 10 evenly spaced values between 0.01 and 0.1\n",
    "        'n_estimators': np.arange(50, 500, 50),  # Range from 50 to 200 with a step of 50'num_leaves': [2,4,6,8,10,12,14,16,24],\n",
    "        'min_child_samples': np.arange(5,20,1),\n",
    "        'subsample': [0.8],\n",
    "        'colsample_bytree': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "        'subsample_freq': [2,3,5,10],\n",
    "        'reg_alpha': np.arange(0,.5,0.01),\n",
    "        'reg_lambda': np.arange(0,.5,0.01),\n",
    "        }\n",
    "    \n",
    "    # Goal: Shuffle data and randomly split Tmp and test data 10 times\n",
    "    for i in range(1, number+1):\n",
    "        # Shuffle and randomly split into Tmp and Test data \n",
    "        X_Tmp, X_Test, Y_Tmp, Y_Test = train_test_split(X, Y, test_size=0.2, train_size=0.8, random_state=None, shuffle=True)\n",
    "        \n",
    "        # Permute the target variable for the random model\n",
    "        Y_tmp_perm = np.random.permutation(Y_Tmp)\n",
    "        \n",
    "        # Make our real model\n",
    "        lgb_model = lgb.LGBMRegressor(boosting_type='gbdt', objective='regression')\n",
    "\n",
    "        # Set up GridSearchCV for the real model\n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator=lgb_model,\n",
    "            param_distributions=param_grid,\n",
    "            n_iter=300,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            cv=5,\n",
    "            verbose=0,\n",
    "            n_jobs=-1)\n",
    "        \n",
    "        # Fit the real model\n",
    "        random_search.fit(X_Tmp, Y_Tmp)\n",
    "        best_models.append(random_search.best_estimator_)\n",
    "        \n",
    "        # Compute SHAP values for the real model\n",
    "        explainer_real = shap.Explainer(best_models[-1])  # Create a SHAP explainer\n",
    "        shap_values_real = explainer_real(X_Test)  # Calculate SHAP values\n",
    "        \n",
    "        # Save SHAP values for the real model\n",
    "        np.save(f'RandomSplit_shap_values_real_round_{i}.npy', shap_values_real.values)  # Save SHAP values\n",
    "        # Optionally, save the actual data for inspection\n",
    "        np.save(f'shap_data_round_{i}.npy', X_Test)\n",
    "\n",
    "        # Save summary plot for the real model\n",
    "        plt.figure()\n",
    "        shap.summary_plot(shap_values_real, X_Test, show=False)\n",
    "        plt.title(f'RandomSplit SHAP Summary Plot - Real Model - Round {i}')\n",
    "        plt.savefig(f'Random_split_shap_summary_real_round_{i}.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Collect scores for the real model\n",
    "        Y_pred_real = random_search.best_estimator_.predict(X_Test)\n",
    "        testing_mse = mean_squared_error(Y_Test, Y_pred_real)\n",
    "        test_scores_list.append(testing_mse)\n",
    "        r2 = r2_score(Y_Test, Y_pred_real)\n",
    "        r2_list.append(r2)\n",
    "        validation_score = random_search.best_score_\n",
    "        validation_score_list.append(validation_score)\n",
    "        Residuals = Y_Test - Y_pred_real\n",
    "\n",
    "        # Make our random model\n",
    "        random_model = lgb.LGBMRegressor(boosting_type='gbdt', objective='regression')\n",
    "        \n",
    "        # Set up GridSearchCV for the random model\n",
    "        random_search_rm = RandomizedSearchCV(\n",
    "            estimator=random_model,\n",
    "            param_distributions=param_grid,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            cv=5,\n",
    "            verbose=0,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Fit the random model\n",
    "        random_search_rm.fit(X_Tmp, Y_tmp_perm)\n",
    "        random_best_models.append(random_search_rm.best_estimator_)\n",
    "        \n",
    "        # Collect scores for the random model\n",
    "        random_Y_pred = random_search_rm.best_estimator_.predict(X_Test)\n",
    "        random_testing_mse = mean_squared_error(Y_Test, random_Y_pred)\n",
    "        random_test_scores_list.append(random_testing_mse)\n",
    "        random_r2 = r2_score(Y_Test, random_Y_pred)\n",
    "        random_r2_list.append(random_r2)\n",
    "        random_validation_score = random_search_rm.best_score_\n",
    "        random_valid_score_list.append(random_validation_score)\n",
    "        \n",
    "\n",
    "        # Time of subplots!!!!\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12, 5))  # Adjust figsize as needed\n",
    "\n",
    "        # Plot for the real model\n",
    "        axs[0].scatter(Y_Test, Y_pred_real, color='blue', label='Lightgbm', alpha=0.6)\n",
    "        axs[0].scatter(Y_Test, random_Y_pred, color='orange', label='Random Model', alpha=0.6)\n",
    "        axs[0].plot([Y_Test.min(), Y_Test.max()], [Y_Test.min(), Y_Test.max()], 'r--', lw=2)\n",
    "        axs[0].set_title(f'Real Model - Round {i}')\n",
    "        axs[0].set_xlabel('Actual Values')\n",
    "        axs[0].set_ylabel('Predicted Values')\n",
    "        axs[0].legend()\n",
    "        axs[0].axis('equal')  # Set equal scaling\n",
    "\n",
    "        # Plot for the real model\n",
    "        axs[1].scatter(Y_pred_real,Residuals, color='blue', label='Residuals', alpha=0.6)\n",
    "        axs[1].axhline(y=0, color='red', linestyle='--', lw=2)  # Horizontal line at 0\n",
    "        axs[1].set_title(f'Real Model - Round {i}')\n",
    "        axs[1].set_xlabel('Predicted Values')\n",
    "        axs[1].set_ylabel('Residuals (Y_test - Y_pred)')\n",
    "        axs[1].legend()\n",
    "        axs[1].axis('equal')  # Set equal scaling\n",
    "        axs[1].grid()\n",
    "\n",
    "        # Show the plot\n",
    "        plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "        plt.savefig(f'RandomSplit_plot_round_{i}.png')  # Save each plot as an image\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    return best_models, validation_score_list, test_scores_list, r2_list, random_best_models, random_valid_score_list, random_test_scores_list, random_r2_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aad25d-28c0-4597-8af7-21d722397cb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_models, validation_score_list, test_scores_list, r2_list, random_best_models, random_valid_score_list, random_test_scores_list, random_r2_list = Random_split(Full_data_copy,10)\n",
    "number=10\n",
    "columns= np.arange(1,number+1,1)\n",
    "RS_table = pd.DataFrame([validation_score_list,test_scores_list, r2_list],index=['validation_score','test_score','R2'],columns=columns)\n",
    "Random_RS_model_table = pd.DataFrame([random_valid_score_list,random_test_scores_list,random_r2_list],index=['validation_score','test_score','R2'],columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75efbdad-ab8b-4098-a1a5-b26052b41484",
   "metadata": {},
   "outputs": [],
   "source": [
    "RS_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6add0a13-469e-4f90-80bb-07af0317ceb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r2_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0face28f-dc41-4afb-811b-de07815caef7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_models[4].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c986e4da-6a33-4bdb-88a7-28b20d18a85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models[0].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f752da2-8af6-473f-b5f9-193ce3832542",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models[1].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c48fb6-6cac-4fc3-b7c0-a40d423f6aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extracting validation scores and test scores for both models\n",
    "validation_scores = RS_table.loc['validation_score'].values\n",
    "validation_scores = [-score for score in validation_score_list]\n",
    "random_validation_scores = Random_RS_model_table.loc['validation_score'].values\n",
    "random_validation_scores = [-score for score in random_valid_score_list]\n",
    "test_scores = RS_table.loc['test_score'].values\n",
    "random_test_scores = Random_RS_model_table.loc['test_score'].values\n",
    "\n",
    "# Perform Mann-Whitney U test on validation scores\n",
    "u_statistic_validation, p_value_validation = mannwhitneyu(validation_scores, random_validation_scores)\n",
    "\n",
    "# Perform Mann-Whitney U test on test scores\n",
    "u_statistic_test, p_value_test = mannwhitneyu(test_scores, random_test_scores)\n",
    "\n",
    "# Print results\n",
    "print(f'Mann-Whitney U Test on Validation Scores: U-statistic = {u_statistic_validation}, p-value = {p_value_validation}')\n",
    "print(f'Mann-Whitney U Test on Test Scores: U-statistic = {u_statistic_test}, p-value = {p_value_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c7a71b-335f-42f1-b1b0-444c6b988e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for visualization\n",
    "data = {\n",
    "    'Model Type': ['LightGBM'] * len(validation_scores) + ['Random Model'] * len(random_validation_scores),\n",
    "    'Validation Score': np.concatenate([validation_scores, random_validation_scores]),\n",
    "    'Test Score': np.concatenate([test_scores, random_test_scores])\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "scores_df = pd.DataFrame(data)\n",
    "\n",
    "# Set the aesthetics for the plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a boxplot for Validation Scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(x='Model Type', y='Validation Score', data=scores_df)\n",
    "plt.title('Validation Data Performance')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Model Type')\n",
    "\n",
    "# Create a boxplot for Test Scores\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x='Model Type', y='Test Score', data=scores_df)\n",
    "plt.title('Performance on Testing Data')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Model Type')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b6afad-8e6c-438f-b73e-8412e8bda4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a violin plot for Validation Scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.violinplot(x='Model Type', y='Validation Score', data=scores_df)\n",
    "plt.title('Validation Scores Violin Plot')\n",
    "plt.ylabel('Validation Score')\n",
    "plt.xlabel('Model Type')\n",
    "\n",
    "# Create a violin plot for Test Scores\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.violinplot(x='Model Type', y='Test Score', data=scores_df)\n",
    "plt.title('Test Scores Violin Plot')\n",
    "plt.ylabel('Test Score')\n",
    "plt.xlabel('Model Type')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1be600-1bf0-4de4-b70a-f7f2cfc5d5d4",
   "metadata": {},
   "source": [
    "### Group by Patient ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e8da7d-2038-4a70-b5c7-35df9bd42091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Group_by_Patient(data,number):\n",
    "    # Separate the data into features and target (X and Y)\n",
    "    X = data.drop(columns=['run_accession', 'SubjectID_child', 'visitlabel', 'Ecoli_GR'])\n",
    "    # Target variable (Ecoli_Growth_rate)\n",
    "    Y = data['Ecoli_GR']\n",
    "    groups = data['SubjectID_child']\n",
    "    \n",
    "    # Set up lists for model performance\n",
    "    best_models = []   \n",
    "    validation_score_list = []\n",
    "    test_scores_list = []\n",
    "    r2_list = []\n",
    "    \n",
    "    # Set up lists for the random model\n",
    "    random_best_models = []\n",
    "    random_valid_score_list = []\n",
    "    random_test_scores_list = []\n",
    "    random_r2_list = []\n",
    "\n",
    "    # Make our real model\n",
    "    lgb_model = lgb.LGBMRegressor(boosting_type='gbdt', objective='regression')\n",
    "    # Define hyperparameters grid for the real model\n",
    "    param_grid = {\n",
    "        'num_leaves': np.arange(2, 12, 2),  # Range from 2 to 24 with a step of 2\n",
    "        'max_depth': np.arange(2, 30),  # Range from 1 to 10\n",
    "        #'min_split_gain': np.arange(0,.5,.01),\n",
    "        'learning_rate': np.arange(0.01, 0.07, .001),  # 10 evenly spaced values between 0.01 and 0.1\n",
    "        'n_estimators': np.arange(50, 500, 50),  # Range from 50 to 200 with a step of 50'num_leaves': [2,4,6,8,10,12,14,16,24],\n",
    "        'min_child_samples': np.arange(1,5,1),\n",
    "        'subsample': [0.8],\n",
    "        'colsample_bytree': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "        'subsample_freq': [2,3,5,10],\n",
    "        'reg_alpha': np.arange(0,.5,0.01),\n",
    "        'reg_lambda': np.arange(0,.5,0.01),\n",
    "        }\n",
    "    \n",
    "    # Goal: Shuffle data and randomly split Tmp and test data 10 times\n",
    "    for i in range(1, number+1):\n",
    "        # Shuffle and randomly split into Tmp and Test data \n",
    "        gss=GroupShuffleSplit(n_splits=1,test_size=0.2,train_size=0.7)\n",
    "        \n",
    "        train_idx, test_idx = next(gss.split(X, Y, groups))\n",
    "        X_Tmp = X.loc[train_idx]\n",
    "        X_Test = X.loc[test_idx]\n",
    "        Y_Tmp = Y.loc[train_idx]\n",
    "        Y_Test = Y.loc[test_idx]\n",
    "        \n",
    "        # Permute the target variable for the random model\n",
    "        Y_tmp_perm = np.random.permutation(Y_Tmp)\n",
    "        \n",
    "        # Make our real model\n",
    "        lgb_model = lgb.LGBMRegressor(boosting_type='gbdt', objective='regression')\n",
    "        \n",
    "        group_kfold = GroupKFold(n_splits=5)\n",
    "        \n",
    "        # Set up RandomizedSearchCV for the real model\n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator=lgb_model,\n",
    "            param_distributions=param_grid,\n",
    "            n_iter=300,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            cv=group_kfold,  # Use the group_kfold instance here\n",
    "            verbose=0,\n",
    "            n_jobs=-1)\n",
    "\n",
    "        # Fit the model (assuming X_Tmp, Y_Tmp, and groups are defined)\n",
    "        random_search.fit(X_Tmp, Y_Tmp, groups=groups.loc[train_idx])\n",
    "        best_models.append(random_search.best_estimator_)\n",
    "\n",
    "        # Compute SHAP values for the real model\n",
    "        explainer_real = shap.Explainer(best_models[-1])  # Create a SHAP explainer\n",
    "        shap_values_real = explainer_real(X_Test)  # Calculate SHAP values\n",
    "        \n",
    "        # Save SHAP values for the real model\n",
    "        np.save(f'GroupbyPatient_shap_values_real_round_{i}.npy', shap_values_real.values)  # Save SHAP values\n",
    "        # Optionally, save the actual data for inspection\n",
    "        np.save(f'GroupbyPatient_shap_data_round_{i}.npy', X_Test)\n",
    "        ##np.save(f'GroupbyPatient_shap_data_round_{i}.npy', X_Test((indexes))\n",
    "        \n",
    "        # Save summary plot for the real model\n",
    "        plt.figure()\n",
    "        shap.summary_plot(shap_values_real, X_Test, show=False)\n",
    "        plt.title(f'GroupbyPatient SHAP Summary Plot - Real Model - Round {i}')\n",
    "        plt.savefig(f'GroupbyPatient_shap_summary_real_round_{i}.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Collect scores for the real model\n",
    "        Y_pred_real = random_search.best_estimator_.predict(X_Test)\n",
    "        testing_mse = mean_squared_error(Y_Test, Y_pred_real)\n",
    "        test_scores_list.append(testing_mse)\n",
    "        r2 = r2_score(Y_Test, Y_pred_real)\n",
    "        r2_list.append(r2)\n",
    "        validation_score = random_search.best_score_\n",
    "        validation_score_list.append(validation_score)\n",
    "        Residuals = Y_Test - Y_pred_real\n",
    "        \n",
    "\n",
    "        # Make our random model\n",
    "        random_model = lgb.LGBMRegressor(boosting_type='gbdt', objective='regression')\n",
    "        \n",
    "        # Set up RandomizedSearchCV for the real model\n",
    "        random_search_rm = RandomizedSearchCV(\n",
    "            estimator=lgb_model,\n",
    "            param_distributions=param_grid,\n",
    "            n_iter=300,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            cv=group_kfold,  # Use the group_kfold instance here\n",
    "            verbose=0,\n",
    "            n_jobs=-1)\n",
    "\n",
    "        \n",
    "        # Fit the random model\n",
    "        random_search_rm.fit(X_Tmp, Y_tmp_perm,groups=groups.loc[train_idx])\n",
    "        random_best_models.append(random_search_rm.best_estimator_)\n",
    "        \n",
    "        # Collect scores for the random model\n",
    "        random_Y_pred = random_search_rm.best_estimator_.predict(X_Test)\n",
    "        random_testing_mse = mean_squared_error(Y_Test, random_Y_pred)\n",
    "        random_test_scores_list.append(random_testing_mse)\n",
    "        random_r2 = r2_score(Y_Test, random_Y_pred)\n",
    "        random_r2_list.append(random_r2)\n",
    "        random_validation_score = random_search_rm.best_score_\n",
    "        random_valid_score_list.append(random_validation_score)\n",
    "        \n",
    "\n",
    "        # Time of subplots!!!!\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12, 5))  # Adjust figsize as needed\n",
    "\n",
    "        # Plot for the real model\n",
    "        axs[0].scatter(Y_Test, Y_pred_real, color='blue', label='LightGBM', alpha=0.6)\n",
    "        axs[0].scatter(Y_Test, random_Y_pred, color='orange', label='Random Model', alpha=0.6)\n",
    "        axs[0].plot([Y_Test.min(), Y_Test.max()], [Y_Test.min(), Y_Test.max()], 'r--', lw=2)\n",
    "        axs[0].set_title(f'Real Model - Round {i}')\n",
    "        axs[0].set_xlabel('Actual Values')\n",
    "        axs[0].set_ylabel('Predicted Values')\n",
    "        axs[0].legend()\n",
    "        axs[0].axis('equal')  # Set equal scaling\n",
    "\n",
    "        # Plot for the real model\n",
    "        axs[1].scatter(Y_pred_real,Residuals, color='blue', label='Residuals', alpha=0.6)\n",
    "        axs[1].axhline(y=0, color='red', linestyle='--', lw=2)  # Horizontal line at 0\n",
    "        axs[1].set_title(f'Real Model - Round {i}')\n",
    "        axs[1].set_xlabel('Predicted Values')\n",
    "        axs[1].set_ylabel('Residuals (Y_test - Y_pred)')\n",
    "        axs[1].legend()\n",
    "        axs[1].axis('equal')  # Set equal scaling\n",
    "        axs[1].grid()\n",
    "\n",
    "        # Show the plot\n",
    "        plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "        plt.savefig(f'GroupbyPatient_plot_round_{i}.png')  # Save each plot as an image\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    return best_models, validation_score_list, test_scores_list, r2_list, random_best_models, random_valid_score_list, random_test_scores_list, random_r2_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7730781-2c16-4e23-bd6b-8e71c088033e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_models_GP, validation_score_list_GP, test_scores_list_GP, r2_list_GP, random_best_models_GP, random_valid_score_list_GP, random_test_scores_list_GP, random_r2_list_GP = Group_by_Patient(Full_data_copy,10)\n",
    "number=10\n",
    "columns= np.arange(1,number+1,1)\n",
    "GP_table = pd.DataFrame([validation_score_list_GP,test_scores_list_GP, r2_list_GP],index=['validation_score','test_score','R2'],columns=columns)\n",
    "Random_GP_model_table = pd.DataFrame([random_valid_score_list_GP,random_test_scores_list_GP,random_r2_list_GP],index=['validation_score','test_score','R2'],columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae87c414-e2a3-49bd-8859-b9e8afa2c8de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GP_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850c7259-d883-42eb-9d08-62fe112d4117",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_GP[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c35f12-6e87-4d69-b3c1-0c7532c5e7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_GP[1].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d5ec09-c388-4520-898e-2ae444e58081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting validation scores and test scores for both models\n",
    "validation_scores = GP_table.loc['validation_score'].values\n",
    "validation_scores = [-score for score in validation_score_list_GP]\n",
    "random_validation_scores = Random_GP_model_table.loc['validation_score'].values\n",
    "random_validation_scores = [-score for score in random_valid_score_list_GP]\n",
    "test_scores = GP_table.loc['test_score'].values\n",
    "random_test_scores = Random_GP_model_table.loc['test_score'].values\n",
    "\n",
    "# Perform Mann-Whitney U test on validation scores\n",
    "u_statistic_validation, p_value_validation = mannwhitneyu(validation_scores, random_validation_scores)\n",
    "\n",
    "# Perform Mann-Whitney U test on test scores\n",
    "u_statistic_test, p_value_test = mannwhitneyu(test_scores, random_test_scores)\n",
    "\n",
    "# Print results\n",
    "print(f'Mann-Whitney U Test on Validation Scores: U-statistic = {u_statistic_validation}, p-value = {p_value_validation}')\n",
    "print(f'Mann-Whitney U Test on Test Scores: U-statistic = {u_statistic_test}, p-value = {p_value_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b578fb-3dd4-48fd-91a0-9be22c6d7b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83101fff-6c0e-4c99-8971-80e5d5aced6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for visualization\n",
    "data = {\n",
    "    'Model Type': ['LightGBM'] * len(validation_scores) + ['Random Model'] * len(random_validation_scores),\n",
    "    'Validation Score': np.concatenate([validation_scores, random_validation_scores]),\n",
    "    'Test Score': np.concatenate([test_scores, random_test_scores])\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "scores_df = pd.DataFrame(data)\n",
    "\n",
    "# Set the aesthetics for the plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a boxplot for Validation Scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(x='Model Type', y='Validation Score', data=scores_df)\n",
    "plt.title('Validation Data Performance')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Model Type')\n",
    "\n",
    "# Create a boxplot for Test Scores\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x='Model Type', y='Test Score', data=scores_df)\n",
    "plt.title('Performance on Testing Data')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Model Type')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8783dc-f345-4e18-86ca-4266fbbd35de",
   "metadata": {},
   "source": [
    "### Group by Time point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6d4152-6f44-4879-b570-168518bfe801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Group_by_Time(data,number):\n",
    "    # Separate the data into features and target (X and Y)\n",
    "    X = data.drop(columns=['run_accession', 'SubjectID_child', 'visitlabel', 'Ecoli_GR'])\n",
    "    # Target variable (Ecoli_Growth_rate)\n",
    "    Y = data['Ecoli_GR']\n",
    "    groups = data['visitlabel']\n",
    "    \n",
    "    # Set up lists for model performance\n",
    "    best_models = []   \n",
    "    validation_score_list = []\n",
    "    test_scores_list = []\n",
    "    r2_list = []\n",
    "    \n",
    "    # Set up lists for the random model\n",
    "    random_best_models = []\n",
    "    random_valid_score_list = []\n",
    "    random_test_scores_list = []\n",
    "    random_r2_list = []\n",
    "\n",
    "    # Define hyperparameters grid for the real model\n",
    "    param_grid = {\n",
    "        'num_leaves': np.arange(2, 12, 2),  # Range from 2 to 24 with a step of 2\n",
    "        'max_depth': np.arange(2, 30),  # Range from 1 to 10\n",
    "        #'min_split_gain': np.arange(0,.5,.01),\n",
    "        'learning_rate': np.arange(0.01, 0.07, .001),  # 10 evenly spaced values between 0.01 and 0.1\n",
    "        'n_estimators': np.arange(50, 500, 50),  # Range from 50 to 200 with a step of 50'num_leaves': [2,4,6,8,10,12,14,16,24],\n",
    "        'min_child_samples': np.arange(1,5,1),\n",
    "        'subsample': [0.8],\n",
    "        'colsample_bytree': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "        'subsample_freq': [2,3,5,10],\n",
    "        'reg_alpha': np.arange(0,.5,0.01),\n",
    "        'reg_lambda': np.arange(0,.5,0.01),\n",
    "        }\n",
    "    \n",
    "    # Goal: Shuffle data and randomly split Tmp and test data 10 times\n",
    "    for i in range(1, number+1):\n",
    "        # Shuffle and randomly split into Tmp and Test data \n",
    "        gss=GroupShuffleSplit(n_splits=1,test_size=0.2,train_size=0.8)\n",
    "        \n",
    "        train_idx, test_idx = next(gss.split(X, Y, groups))\n",
    "        X_Tmp = X.loc[train_idx]\n",
    "        X_Test = X.loc[test_idx]\n",
    "        Y_Tmp = Y.loc[train_idx]\n",
    "        Y_Test = Y.loc[test_idx]\n",
    "        \n",
    "        # Permute the target variable for the random model\n",
    "        Y_tmp_perm = np.random.permutation(Y_Tmp)\n",
    "        \n",
    "        # Make our real model\n",
    "        lgb_model = lgb.LGBMRegressor(boosting_type='gbdt', objective='regression')\n",
    "        \n",
    "        group_kfold = GroupKFold(n_splits=4)\n",
    "\n",
    "        # Set up RandomizedSearchCV for the real model\n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator=lgb_model,\n",
    "            param_distributions=param_grid,\n",
    "            n_iter=300,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            cv=group_kfold,  # Use the group_kfold instance here\n",
    "            verbose=0,\n",
    "            n_jobs=-1)\n",
    "\n",
    "        \n",
    "        # Fit the real model\n",
    "        random_search.fit(X_Tmp, Y_Tmp,groups=groups.loc[train_idx])\n",
    "        best_models.append(random_search.best_estimator_)\n",
    "\n",
    "        # Compute SHAP values for the real model\n",
    "        explainer_real = shap.Explainer(best_models[-1])  # Create a SHAP explainer\n",
    "        shap_values_real = explainer_real(X_Test)  # Calculate SHAP values\n",
    "        \n",
    "        # Save SHAP values for the real model\n",
    "        np.save(f'GroupbyTime_shap_values_real_round_{i}.npy', shap_values_real.values)  # Save SHAP values\n",
    "        # Optionally, save the actual data for inspection\n",
    "        np.save(f'GroupbyTime_shap_data_round_{i}.npy', X_Test)\n",
    "\n",
    "        # Save summary plot for the real model\n",
    "        plt.figure()\n",
    "        shap.summary_plot(shap_values_real, X_Test, show=False)\n",
    "        plt.title(f'GroupbyTime SHAP Summary Plot - Real Model - Round {i}')\n",
    "        plt.savefig(f'GroupbyTime_shap_summary_real_round_{i}.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Collect scores for the real model\n",
    "        Y_pred_real = random_search.best_estimator_.predict(X_Test)\n",
    "        testing_mse = mean_squared_error(Y_Test, Y_pred_real)\n",
    "        test_scores_list.append(testing_mse)\n",
    "        r2 = r2_score(Y_Test, Y_pred_real)\n",
    "        r2_list.append(r2)\n",
    "        validation_score = random_search.best_score_\n",
    "        validation_score_list.append(validation_score)\n",
    "        Residuals = Y_Test - Y_pred_real\n",
    "        \n",
    "\n",
    "        # Make our random model\n",
    "        random_model = lgb.LGBMRegressor(boosting_type='gbdt', objective='regression')\n",
    "        \n",
    "        # Set up GridSearchCV for the random model\n",
    "        random_search_rm = RandomizedSearchCV(\n",
    "            estimator=lgb_model,\n",
    "            param_distributions=param_grid,\n",
    "            n_iter=300,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            cv=group_kfold,  # Use the group_kfold instance here\n",
    "            verbose=0,\n",
    "            n_jobs=-1)\n",
    "        \n",
    "        # Fit the random model\n",
    "        random_search_rm.fit(X_Tmp, Y_tmp_perm,groups=groups.loc[train_idx])\n",
    "        random_best_models.append(random_search_rm.best_estimator_)\n",
    "        \n",
    "        # Collect scores for the random model\n",
    "        random_Y_pred = random_search_rm.best_estimator_.predict(X_Test)\n",
    "        random_testing_mse = mean_squared_error(Y_Test, random_Y_pred)\n",
    "        random_test_scores_list.append(random_testing_mse)\n",
    "        random_r2 = r2_score(Y_Test, random_Y_pred)\n",
    "        random_r2_list.append(random_r2)\n",
    "        random_validation_score = random_search_rm.best_score_\n",
    "        random_valid_score_list.append(random_validation_score)\n",
    "        \n",
    "\n",
    "        # Time of subplots!!!!\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12, 5))  # Adjust figsize as needed\n",
    "\n",
    "        # Plot for the real model\n",
    "        axs[0].scatter(Y_Test, Y_pred_real, color='blue', label='LightGBM', alpha=0.6)\n",
    "        axs[0].scatter(Y_Test, random_Y_pred, color='orange', label='Random Model', alpha=0.6)\n",
    "        axs[0].plot([Y_Test.min(), Y_Test.max()], [Y_Test.min(), Y_Test.max()], 'r--', lw=2)\n",
    "        axs[0].set_title(f'Real Model - Round {i}')\n",
    "        axs[0].set_xlabel('Actual Values')\n",
    "        axs[0].set_ylabel('Predicted Values')\n",
    "        axs[0].legend()\n",
    "        axs[0].axis('equal')  # Set equal scaling\n",
    "\n",
    "        # Plot for the real model\n",
    "        axs[1].scatter(Y_pred_real,Residuals, color='blue', label='Residuals', alpha=0.6)\n",
    "        axs[1].axhline(y=0, color='red', linestyle='--', lw=2)  # Horizontal line at 0\n",
    "        axs[1].set_title(f'Real Model - Round {i}')\n",
    "        axs[1].set_xlabel('Predicted Values')\n",
    "        axs[1].set_ylabel('Residuals (Y_test - Y_pred)')\n",
    "        axs[1].legend()\n",
    "        axs[1].axis('equal')  # Set equal scaling\n",
    "        axs[1].grid()\n",
    "        \n",
    "        # Show the plot\n",
    "        plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "        plt.savefig(f'GroupbyTime_plot_round_{i}.png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    return best_models, validation_score_list, test_scores_list, r2_list, random_best_models, random_valid_score_list, random_test_scores_list, random_r2_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545316dc-d9a6-487e-9b80-19e06e283c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_GT, validation_score_list_GT, test_scores_list_GT, r2_list_GT, random_best_models_GT, random_valid_score_list_GT, random_test_scores_list_GT, random_r2_list_GT = Group_by_Time(Full_data_copy,10)\n",
    "number=10\n",
    "columns= np.arange(1,number+1,1)\n",
    "GT_table = pd.DataFrame([validation_score_list_GT,test_scores_list_GT, r2_list_GT],index=['validation_score','test_score','R2'],columns=columns)\n",
    "Random_GT_model_table = pd.DataFrame([random_valid_score_list_GT,random_test_scores_list_GT,random_r2_list_GT],index=['validation_score','test_score','R2'],columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1406f96-f5ac-4db4-8e26-f0ad12357d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787ac62e-84e6-4d33-9c29-3e7349c8614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_best_models_GT[4].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3dfe3e-318e-4c3d-94f1-0733edd6c5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting validation scores and test scores for both models\n",
    "validation_scores = GT_table.loc['validation_score'].values\n",
    "validation_scores = [-score for score in validation_score_list_GT]\n",
    "random_validation_scores = Random_GT_model_table.loc['validation_score'].values\n",
    "random_validation_scores = [-score for score in random_valid_score_list_GT]\n",
    "test_scores = GT_table.loc['test_score'].values\n",
    "random_test_scores = Random_GT_model_table.loc['test_score'].values\n",
    "\n",
    "# Perform Mann-Whitney U test on validation scores\n",
    "u_statistic_validation, p_value_validation = mannwhitneyu(validation_scores, random_validation_scores)\n",
    "\n",
    "# Perform Mann-Whitney U test on test scores\n",
    "u_statistic_test, p_value_test = mannwhitneyu(test_scores, random_test_scores)\n",
    "\n",
    "# Print results\n",
    "print(f'Mann-Whitney U Test on Validation Scores: U-statistic = {u_statistic_validation}, p-value = {p_value_validation}')\n",
    "print(f'Mann-Whitney U Test on Test Scores: U-statistic = {u_statistic_test}, p-value = {p_value_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ec3c71-7f80-41cd-b5ed-70c89ddd72e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for visualization\n",
    "data = {\n",
    "    'Model Type': ['LightGBM'] * len(validation_scores) + ['Random Model'] * len(random_validation_scores),\n",
    "    'Validation Score': np.concatenate([validation_scores, random_validation_scores]),\n",
    "    'Test Score': np.concatenate([test_scores, random_test_scores])\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "scores_df = pd.DataFrame(data)\n",
    "\n",
    "# Set the aesthetics for the plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a boxplot for Validation Scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(x='Model Type', y='Validation Score', data=scores_df)\n",
    "plt.title('Validation Data Performance')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Model Type')\n",
    "\n",
    "# Create a boxplot for Test Scores\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x='Model Type', y='Test Score', data=scores_df)\n",
    "plt.title('Performance on Testing Data')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Model Type')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f8879e-a0aa-4226-8ef0-6644e2dbffc1",
   "metadata": {},
   "source": [
    "### Group by Time point and patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8943e1-9265-4e94-b2da-88b982524f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ca679c-7ad7-41db-996a-9a8d4c6f5bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b34f589-72f1-4ab1-a69a-334b9885a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Goal: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd32f4f-627f-4a2b-8038-31550c88aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "met_data = Full_data_copy[['run_accession','SubjectID_child','visitlabel']]\n",
    "\n",
    "met_df = met_data.pivot(index='SubjectID_child', columns='visitlabel',values='run_accession')\n",
    "\n",
    "#put in function form\n",
    "\n",
    "#this will beed to be in a for loop to get multiple tmp,test \n",
    "met_df = met_df.sample(frac=1,random_state=42)\n",
    "split_index = int(0.8*len(met_df))\n",
    "train_df = met_df.iloc[:split_index]\n",
    "test_df = met_df.iloc[split_index:]\n",
    "train_M1_6_df = train_df.drop(columns=['M12','M18'])\n",
    "Train_M1_6_df = train_M1_6_df.reset_index() \n",
    "err_numbers_train = Train_M1_6_df[['M01', 'M03', 'M06']].stack().tolist()\n",
    "\n",
    "test_M1_6_df = test_df.drop(columns=['M01','M03','M06'])\n",
    "Test_M1_6_df = test_M1_6_df.reset_index() \n",
    "err_numbers_test =Test_M1_6_df[['M12','M18']].stack().tolist()\n",
    "\n",
    "train_df = Full_data_copy[Full_data_copy['run_accession'].isin(err_numbers_train)]\n",
    "testing_df = Full_data_copy[Full_data_copy['run_accession'].isin(err_numbers_test)]\n",
    "\n",
    "Train_df = train_df.drop(columns=['run_accession','SubjectID_child','visitlabel'])\n",
    "Y_train_df = Train_df['Ecoli_GR']\n",
    "\n",
    "Test_df = testing_df.drop(columns=['run_accession','SubjectID_child','visitlabel'])\n",
    "Y_Test_df = Test_df['Ecoli_GR']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f4690b-4221-4ac9-9b4b-490b1cc5d6b2",
   "metadata": {},
   "source": [
    "# Machine Learning Model with CV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd472dda-8c2c-49e5-8a4c-bb99da24d3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_split(data,number):\n",
    "    # Separate the data into features and target (X and Y)\n",
    "    X = data.drop(columns=['run_accession', 'SubjectID_child', 'visitlabel', 'Ecoli_GR'])\n",
    "    # Target variable (Ecoli_Growth_rate)\n",
    "    Y = data['Ecoli_GR']\n",
    "    \n",
    "    # Set up lists for model performance\n",
    "    best_models = []   \n",
    "    validation_score_list = []\n",
    "    test_scores_list = []\n",
    "    r2_list = []\n",
    "    \n",
    "    # Set up lists for the random model\n",
    "    random_best_models = []\n",
    "    random_valid_score_list = []\n",
    "    random_test_scores_list = []\n",
    "    random_r2_list = []\n",
    "\n",
    "     # Make our real model\n",
    "    lgb_model = lgb.LGBMRegressor(boosting_type='gbdt', objective='regression')\n",
    "    # Define hyperparameters grid for the real model\n",
    "    param_grid = {\n",
    "        'num_leaves': [2,4,6,8,10,12,14,16,24],\n",
    "            #'max_depth': [10, 50, 100],\n",
    "            #'learning_rate': [0.01, 0.03,.05],\n",
    "            #'n_estimators': [50, 100,150],\n",
    "    }\n",
    "        \n",
    "    # Set up GridSearchCV for the real model\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=lgb_model,\n",
    "        param_grid=param_grid,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        cv=5,\n",
    "        verbose=0,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Goal: Shuffle data and randomly split Tmp and test data 10 times\n",
    "    for i in range(1, number+1):\n",
    "        # Shuffle and randomly split into Tmp and Test data \n",
    "        X_Tmp, X_Test, Y_Tmp, Y_Test = train_test_split(X, Y, test_size=0.2, train_size=0.8, random_state=None, shuffle=True)\n",
    "        \n",
    "        # Permute the target variable for the random model\n",
    "        Y_tmp_perm = np.random.permutation(Y_Tmp)\n",
    "        \n",
    "        # Fit the real model\n",
    "        grid_search.fit(X_Tmp, Y_Tmp)\n",
    "        best_models.append(grid_search.best_estimator_)\n",
    "        \n",
    "        # Compute SHAP values for the real model\n",
    "        explainer_real = shap.Explainer(best_models[-1])  # Create a SHAP explainer\n",
    "        shap_values_real = explainer_real(X_Test)  # Calculate SHAP values\n",
    "        \n",
    "        # Save SHAP values for the real model\n",
    "        np.save(f'RandomSplit_shap_values_real_round_{i}.npy', shap_values_real.values)  # Save SHAP values\n",
    "        # Optionally, save the actual data for inspection\n",
    "        np.save(f'shap_data_round_{i}.npy', X_Test)\n",
    "\n",
    "        # Save summary plot for the real model\n",
    "        plt.figure()\n",
    "        shap.summary_plot(shap_values_real, X_Test, show=False)\n",
    "        plt.title(f'RandomSplit SHAP Summary Plot - Real Model - Round {i}')\n",
    "        plt.savefig(f'Random_split_shap_summary_real_round_{i}.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Collect scores for the real model\n",
    "        Y_pred_real = grid_search.best_estimator_.predict(X_Test)\n",
    "        testing_mse = mean_squared_error(Y_Test, Y_pred_real)\n",
    "        test_scores_list.append(testing_mse)\n",
    "        r2 = r2_score(Y_Test, Y_pred_real)\n",
    "        r2_list.append(r2)\n",
    "        validation_score = grid_search.best_score_\n",
    "        validation_score_list.append(validation_score)\n",
    "        Residuals = Y_Test - Y_pred_real\n",
    "\n",
    "        # Make our random model\n",
    "        random_model = lgb.LGBMRegressor(boosting_type='gbdt', objective='regression')\n",
    "        \n",
    "        # Set up GridSearchCV for the random model\n",
    "        grid_search_rm = GridSearchCV(\n",
    "            estimator=random_model,\n",
    "            param_grid=param_grid,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            cv=5,\n",
    "            verbose=0,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Fit the random model\n",
    "        grid_search_rm.fit(X_Tmp, Y_tmp_perm)\n",
    "        random_best_models.append(grid_search_rm.best_estimator_)\n",
    "        \n",
    "        # Collect scores for the random model\n",
    "        random_Y_pred = grid_search_rm.best_estimator_.predict(X_Test)\n",
    "        random_testing_mse = mean_squared_error(Y_Test, random_Y_pred)\n",
    "        random_test_scores_list.append(random_testing_mse)\n",
    "        random_r2 = r2_score(Y_Test, random_Y_pred)\n",
    "        random_r2_list.append(random_r2)\n",
    "        random_validation_score = grid_search_rm.best_score_\n",
    "        random_valid_score_list.append(random_validation_score)\n",
    "        \n",
    "\n",
    "        # Time of subplots!!!!\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12, 5))  # Adjust figsize as needed\n",
    "\n",
    "        # Plot for the real model\n",
    "        axs[0].scatter(Y_Test, Y_pred_real, color='blue', label='Lightgbm', alpha=0.6)\n",
    "        axs[0].scatter(Y_Test, random_Y_pred, color='orange', label='Random Model', alpha=0.6)\n",
    "        axs[0].plot([Y_Test.min(), Y_Test.max()], [Y_Test.min(), Y_Test.max()], 'r--', lw=2)\n",
    "        axs[0].set_title(f'Real Model - Round {i}')\n",
    "        axs[0].set_xlabel('Actual Values')\n",
    "        axs[0].set_ylabel('Predicted Values')\n",
    "        axs[0].legend()\n",
    "        axs[0].axis('equal')  # Set equal scaling\n",
    "\n",
    "        # Plot for the real model\n",
    "        axs[1].scatter(Y_pred_real,Residuals, color='blue', label='Residuals', alpha=0.6)\n",
    "        axs[1].axhline(y=0, color='red', linestyle='--', lw=2)  # Horizontal line at 0\n",
    "        axs[1].set_title(f'Real Model - Round {i}')\n",
    "        axs[1].set_xlabel('Predicted Values')\n",
    "        axs[1].set_ylabel('Residuals (Y_test - Y_pred)')\n",
    "        axs[1].legend()\n",
    "        axs[1].axis('equal')  # Set equal scaling\n",
    "        axs[1].grid()\n",
    "\n",
    "        # Plot for the random model\n",
    "        #axs[2].scatter(Y_Test, random_Y_pred, color='orange', label='Predicted', alpha=0.6)\n",
    "        #axs[2].plot([Y_Test.min(), Y_Test.max()], [Y_Test.min(), Y_Test.max()], 'r--', lw=2)\n",
    "        #axs[2].set_title(f'Random Model - Round {i}')\n",
    "        #axs[2].set_xlabel('Actual Values')\n",
    "        #axs[2].set_ylabel('Predicted Values')\n",
    "        #axs[2].legend()\n",
    "        #axs[2].axis('equal')  # Set equal scaling\n",
    "\n",
    "        # Show the plot\n",
    "        plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "        plt.savefig(f'RandomSplit_plot_round_{i}.png')  # Save each plot as an image\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    return best_models, validation_score_list, test_scores_list, r2_list, random_best_models, random_valid_score_list, random_test_scores_list, random_r2_list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbcec02-0595-48d8-b403-a8ee5d0f9774",
   "metadata": {},
   "source": [
    "FOr psuedo count\n",
    "additive smoothing (alpha can be anything )\n",
    "laplace smoothing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5206d260-6f18-4f61-9f2e-ed5adeb110a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def light_gbm_set_up():\n",
    "    #Step 4: Set up our Modelllll!! Lightgbm\n",
    "    lgb_model = lgb.LGBMRegressor(boosting_type='gbdt',objective='regression')\n",
    "    # We have t odefine our hyperparameters grid (this is for our random search function)\n",
    "    param_grid = {\n",
    "        'num_leaves': [2, 4, 8],          # Number of leaves in each tree\n",
    "        'max_depth': [10,50,100],           # Maximum tree depth (-1 for no limit)\n",
    "        'learning_rate': [0.05, 0.1,0.2],# Learning rate to adjust how much to correct per iteration\n",
    "        'n_estimators': [50, 100, 150],         # Number of trees (boosting iterations)\n",
    "        #'min_child_samples': [10, 20, 30],       # Minimum number of samples in one leaf\n",
    "        #'subsample': [0.7, 0.8, 1.0],            # Fraction of data to be used for training each tree\n",
    "        #colsample_bytree': [0.7, 0.8, 1.0],     # Fraction of features to use for training each tre\n",
    "    }\n",
    "    return lgb_model,param_grid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26abaedd-5d9e-40e9-ab99-1906532c50c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(choice,data):\n",
    "   \n",
    "    if choice==1:\n",
    "        X_Train, Y_Train, X_Test, Y_test, kf = Random_split(data)\n",
    "        lgb_model,param_grid = light_gbm_set_up()\n",
    "        # Set up GridSearchCV with LightGBM\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=lgb_model,        # LightGBM model\n",
    "            param_grid=param_grid,   # Hyperparameter grid\n",
    "            scoring='neg_mean_squared_error', # Metric to evaluate: negative mean squared error (since it's regression)\n",
    "            cv=kf,                      # GroupKFold CV object (10 folds)\n",
    "            verbose=0,                  # Print results as we go\n",
    "            n_jobs=-1                   # Use all cores\n",
    "        )\n",
    "        # Fit the model\n",
    "        grid_search.fit(X_Train_RS, Y_Train_RS)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        Y_pred = best_model.predict(X.iloc[test_idx])\n",
    "        \n",
    "    if choice==2:\n",
    "        train_idx,X_Train, Y_Train, X_Test, Y_test, kf,groups = Group_by_Patient(data)\n",
    "        lgb_model,param_grid = light_gbm_set_up()\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=lgb_model,        # LightGBM model\n",
    "            param_grid=param_grid,   # Hyperparameter grid\n",
    "            scoring='neg_mean_squared_error', # Metric to evaluate: negative mean squared error (since it's regression)\n",
    "            cv=kf,                      # GroupKFold CV object (10 folds)\n",
    "            verbose=0,                  # Print results as we go\n",
    "            n_jobs=-1                   # Use all cores\n",
    "        )\n",
    "        # Fit the model using Grid_searchSearchCV\n",
    "        # Fit the model with early stopping\n",
    "        # Note: RandomizedSearchCV will call `fit` for each parameter combination\n",
    "        grid_search.fit(X_Train, Y_Train, \n",
    "                        groups=groups.iloc[train_idx])\n",
    "        best_model = grid_search.best_estimator_\n",
    "        Y_pred = best_model.predict(X.iloc[test_idx])\n",
    "        \n",
    "    if choice==3:\n",
    "        train_idx,X_Train, Y_Train, X_Test, Y_test, kf,groups = Group_by_Timepoint(data)\n",
    "        lgb_model,param_grid = light_gbm_set_up()\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=lgb_model,        # LightGBM model\n",
    "            param_grid=param_grid,   # Hyperparameter grid\n",
    "            scoring='neg_mean_squared_error', # Metric to evaluate: negative mean squared error (since it's regression)\n",
    "            cv=kf,                      # GroupKFold CV object (10 folds)\n",
    "            verbose=0,                  # Print results as we go\n",
    "            n_jobs=-1                   # Use all cores\n",
    "        )\n",
    "        # Fit the model using Grid_searchSearchCV\n",
    "        # Fit the model with early stopping\n",
    "        # Note: RandomizedSearchCV will call `fit` for each parameter combination\n",
    "        grid_search.fit(X_Train, Y_Train, \n",
    "                        groups=groups.iloc[train_idx])\n",
    "\n",
    "        best_model = grid_search.best_estimator_\n",
    "        Y_pred = best_model.predict(X.iloc[test_idx])\n",
    "\n",
    "    return best_model, Y_pred\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639c041c-8d90-42aa-9854-fb6a6a9ec0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(choice, data):\n",
    "    # Define the training and test data using different methods based on our choice\n",
    "    if choice == 1:\n",
    "        X_Train, Y_Train, X_Test, Y_test, kf = Random_split(data)\n",
    "    elif choice == 2:\n",
    "        train_idx, X_Train, Y_Train, X_Test, Y_test, kf, groups = Group_by_Patient(data)\n",
    "    elif choice == 3:\n",
    "        train_idx, X_Train, Y_Train, X_Test, Y_test, kf, groups = Group_by_Timepoint(data)\n",
    "\n",
    "    # Model setup\n",
    "    lgb_model, param_grid = light_gbm_set_up()\n",
    "\n",
    "    # Set up GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=lgb_model,\n",
    "        param_grid=param_grid,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        cv=kf,\n",
    "        verbose=0,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Fit the model using GridSearchCV\n",
    "    grid_search.fit(X_Train, Y_Train, groups=groups.iloc[train_idx] if choice != 1 else None)\n",
    "\n",
    "    # Training MSE\n",
    "    best_model = grid_search.best_estimator_\n",
    "    Y_train_pred = best_model.predict(X_Train)\n",
    "    training_mse = mean_squared_error(Y_Train, Y_train_pred)\n",
    "\n",
    "    # Cross-validation MSE\n",
    "    cv_mse = -grid_search.best_score_\n",
    "\n",
    "    # Testing MSE\n",
    "    Y_pred = best_model.predict(X_Test)\n",
    "    testing_mse = mean_squared_error(Y_test, Y_pred)\n",
    "    r2 = r2_score(Y_test, Y_pred)\n",
    "    \n",
    "    return best_model, Y_pred, r2, training_mse, cv_mse, testing_mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a256521c-2d85-461a-805c-72e146da3d98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model, Y_pred, r2, training_mse, cv_mse, testing_mse = model_fit(1,Full_data_copy)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Test Mean Squared Error (MSE): {testing_mse:.4f}\")\n",
    "print(f\"Test R-squared (R): {r2:.4f}\")\n",
    "print('Training mse:',training_mse)\n",
    "print('CV mse:',cv_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f01b3f-d43a-467b-a00e-57f68f5f500d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model, Y_pred, r2, training_mse, cv_mse, testing_mse = model_fit(2,Full_data_copy)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Test Mean Squared Error (MSE): {testing_mse:.4f}\")\n",
    "print(f\"Test R-squared (R): {r2:.4f}\")\n",
    "print('Training mse:',training_mse)\n",
    "print('CV mse:',cv_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47e238c-c6e9-41c6-acf1-963fd266fe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a747dcce-bdff-43af-8d95-294705deb2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, Y_pred, r2, training_mse, cv_mse, testing_mse = model_fit(3,Full_data_copy)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Test Mean Squared Error (MSE): {testing_mse:.4f}\")\n",
    "print(f\"Test R-squared (R): {r2:.4f}\")\n",
    "print('Training mse:',training_mse)\n",
    "print('CV mse:',cv_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847865d5-5bba-4d08-91db-dfd16a105c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dc1893-5e1e-401a-9501-72bd3caac18b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901ab982-fc9d-490f-8dc9-ecb750b98d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Get feature importances from the model\n",
    "importance = best_model.feature_importances_\n",
    "\n",
    "X = Full_data_copy.drop(columns=['run_accession', 'SubjectID_child', 'visitlabel', 'Ecoli_GR'])\n",
    "\n",
    "feature_names = X.columns  # Assuming X_train is a DataFrame\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importance})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 50))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d360a689-e701-468a-aee3-072e52581783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "#Create a SHAP explainer\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "# Summary Plot\n",
    "shap.summary_plot(shap_values, X)\n",
    "\n",
    "# Force Plot for the first instance\n",
    "shap.force_plot(explainer.expected_value, shap_values[0], X.iloc[0])\n",
    "\n",
    "# Dependence Plot for a specific feature (replace 'feature_name' with the actual feature name)\n",
    "shap.dependence_plot('feature_name', shap_values, X)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabd0224-56cd-4d42-ba49-19e963fbab92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a32d680-962d-42ce-aa9d-79eaf9b7b96d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c329185-cbb1-4ad4-a722-0eeabcedc1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
